{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata_path = \\'C:/Users/rafin/Desktop/NSU/NSU 12th Semester/CSE499A.22/Project/Datasets/Apple_Datasets/Apple_BIL/Apple_BIL_Cubes_Test\\'\\n\\nimage_list = []\\nlabel_list = []\\nlabel_int =[]\\n\\nfor i, folder in enumerate(os.listdir(data_path)):\\n    \\n  images = os.listdir(f\"{data_path}/\")\\n  \\n  for row in range(len(images)):\\n      \\n    image_list.append(f\"{data_path}/\" + images[i])\\n    label_list.append(folder)\\n    label_int.append(i)\\n    \\n{i:x for i, x in enumerate(os.listdir(data_path))}\\n\\nsub = pd.DataFrame(image_list)\\nsub.columns = [\"imagename\"]\\n\\nsub[\"label_int\"] = label_int\\nsub[\"label_list\"] = label_list\\n\\nsub.to_csv(\"dataset.csv\")\\n\\nsub.label_int.unique()\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data_path = 'C:/Users/rafin/Desktop/NSU/NSU 12th Semester/CSE499A.22/Project/Datasets/Apple_Datasets/Apple_BIL/Apple_BIL_Cubes_Test'\n",
    "\n",
    "image_list = []\n",
    "label_list = []\n",
    "label_int =[]\n",
    "\n",
    "for i, folder in enumerate(os.listdir(data_path)):\n",
    "    \n",
    "  images = os.listdir(f\"{data_path}/\")\n",
    "  \n",
    "  for row in range(len(images)):\n",
    "      \n",
    "    image_list.append(f\"{data_path}/\" + images[i])\n",
    "    label_list.append(folder)\n",
    "    label_int.append(i)\n",
    "    \n",
    "{i:x for i, x in enumerate(os.listdir(data_path))}\n",
    "\n",
    "sub = pd.DataFrame(image_list)\n",
    "sub.columns = [\"imagename\"]\n",
    "\n",
    "sub[\"label_int\"] = label_int\n",
    "sub[\"label_list\"] = label_list\n",
    "\n",
    "sub.to_csv(\"dataset.csv\")\n",
    "\n",
    "sub.label_int.unique()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/rafin/Desktop/NSU/NSU 12th Semester/CSE499A.22/Project/Datasets/Apple_Datasets/Apple_BIL/Apple_BIL_Cubes_Test'\n",
    "\n",
    "image_list = []\n",
    "label_list = []\n",
    "label_int =[]\n",
    "\n",
    "for i, folder in enumerate(os.listdir(data_path)):\n",
    "  images = os.listdir(f\"{data_path}/\" + folder + \"/\")\n",
    "  for row in range(len(images)):\n",
    "    image_list.append(f\"{data_path}/\" + folder + \"/\" + images[i])\n",
    "    label_list.append(folder)\n",
    "    label_int.append(i)\n",
    "{i:x for i, x in enumerate(os.listdir(data_path))}\n",
    "sub = pd.DataFrame(image_list)\n",
    "sub.columns = [\"imagename\"]\n",
    "sub[\"label_int\"] = label_int\n",
    "sub[\"label_list\"] = label_list\n",
    "\n",
    "sub.to_csv(\"dataset.csv\")\n",
    "sub.label_int.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n",
      "(40, 3) (10, 3)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "X = sub[\"imagename\"].values\n",
    "y = sub[\"label_int\"].values\n",
    "\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "\n",
    "     X_train, X_test = sub.iloc[train_index], sub.iloc[test_index]\n",
    "     y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "print(X.shape)\n",
    "print(X_train.shape , X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 200\n",
    "IMG_WIDTH = 200\n",
    "IMG_CHANNELS = 1\n",
    "IMG_COUNT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchActivate(x):\n",
    "    \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('elu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1,1), padding='same', activation=True):\n",
    "    \n",
    "    x = tf.keras.layers.Conv3D(filters, size, strides=strides, padding=padding,kernel_initializer='Orthogonal')(x)\n",
    "    \n",
    "    if activation == True:\n",
    "        \n",
    "        x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def residual_block_dual(blockInput, num_filters=16, batch_activate = False):\n",
    "\n",
    "    x_side = convolution_block(blockInput, num_filters,(3,3,3))\n",
    "\n",
    "    x = BatchActivate(blockInput)\n",
    "    x1 = convolution_block(x, num_filters, (3,3,3) ,activation=False)\n",
    "\n",
    "    x2 = convolution_block(x1, num_filters, (3,3,3), activation=False)\n",
    "    x2 = BatchActivate(x2)\n",
    "    x2_add = tf.keras.layers.Add()([x1,x2])\n",
    "    \n",
    "    x3 = convolution_block(x2_add, num_filters, (5,5,5), activation=False)\n",
    "    x3 = tf.keras.layers.Add()([x3,x_side])\n",
    "    \n",
    "    x4 = convolution_block(x3, num_filters, (3,3,3), activation=False)\n",
    "\n",
    "#    x = Add()([Squeeze_excitation_layer(x4),x_side])\n",
    "    if batch_activate:\n",
    "        \n",
    "        x4 = BatchActivate(x4)\n",
    "    return x4\n",
    "\n",
    "def residual_block(blockInput, num_filters=16, batch_activate = False):\n",
    "\n",
    "    x_side = convolution_block(blockInput, num_filters,(3,3,3))\n",
    "\n",
    "    x = BatchActivate(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3,3) ,activation=True)\n",
    "#    x = PReLU(shared_axes=[1, 2])(x)\n",
    "\n",
    "    x= convolution_block(x, num_filters, (3,3,3), activation=True)\n",
    "\n",
    "#    x = convolution_block(x, num_filters, (3,3), activation=True)\n",
    "\n",
    "#    x = BatchActivate(x)\n",
    "    x=Squeeze_excitation_layer_3D(x)\n",
    "    \n",
    "    x = tf.keras.layers.Add()([x,x_side])\n",
    "    \n",
    "    if batch_activate:\n",
    "        \n",
    "        x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def Squeeze_excitation_layer_3D(input_x):\n",
    "    \n",
    "    ratio = 4\n",
    "    out_dim =  int(np.shape(input_x)[-1])\n",
    "    \n",
    "    squeeze = tf.keras.layers.GlobalAveragePooling3D()(input_x)\n",
    "    \n",
    "    excitation = tf.keras.layers.Dense(units=int(out_dim / ratio))(squeeze)\n",
    "    excitation = tf.keras.layers.Activation('relu')(excitation)\n",
    "    excitation = tf.keras.layers.Dense(units=out_dim)(excitation)\n",
    "    excitation = tf.keras.layers.Activation('sigmoid')(excitation)\n",
    "    excitation = tf.keras.layers.Reshape([-1,1,1,out_dim])(excitation)\n",
    "    \n",
    "    scale = tf.keras.layers.multiply([input_x, excitation])\n",
    "\n",
    "    return scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet3DClassifier(input_shape=(IMG_COUNT,IMG_HEIGHT, IMG_WIDTH,IMG_CHANNELS),learningRate=0.001,use_se_module=True):\n",
    "\n",
    "    dropout_keep_prob =0.1\n",
    "    '''\n",
    "\n",
    "    Network with multiple attention\n",
    "\n",
    "    '''\n",
    "    start_neurons=32\n",
    "    DropoutRatio = 0.2\n",
    "    inputs = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "\n",
    "\n",
    "#    coord0=CoordinateChannel2D()(inputs)\n",
    "    # 101 -> 50\n",
    "    conv1 = tf.keras.layers.Conv3D(start_neurons, (3,3,3), activation='elu', padding=\"same\")(inputs)\n",
    "    conv1 = residual_block(conv1,start_neurons,True)\n",
    "    conv1 = residual_block(conv1,start_neurons, True)\n",
    "#    conv1=csse_block(conv1,'prefix_conv_1')\n",
    "\n",
    "\n",
    "#    conv1 = nonLocalAttention(conv1)\n",
    "    pool1 = tf.keras.layers.MaxPooling3D((2, 2,2))(conv1)\n",
    "    pool1 = tf.keras.layers.Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    # 50 -> 25\n",
    "    conv2 = tf.keras.layers.Conv3D(start_neurons * 1, (3,3,3), activation='elu', padding=\"same\")(pool1)\n",
    "    conv2 = residual_block(conv2,start_neurons * 1,True)\n",
    "    conv2 = residual_block(conv2,start_neurons * 1, True)\n",
    "\n",
    "    pool2 = tf.keras.layers.MaxPooling3D((2, 2,2))(conv2)\n",
    "    pool2 = tf.keras.layers.Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "#    # 25 -> 12\n",
    "    conv3 = tf.keras.layers.Conv3D(start_neurons * 2, (3,3,3), activation='elu', padding=\"same\")(pool2)\n",
    "    conv3 = residual_block(conv3,start_neurons * 2)\n",
    "    conv3 = residual_block(conv3,start_neurons * 2, True)\n",
    "\n",
    "\n",
    "    pool3 = tf.keras.layers.MaxPooling3D((2,2,2))(conv3)\n",
    "    pool3 = tf.keras.layers.Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "#    # 12 -> 6\n",
    "    conv4 = tf.keras.layers.Conv3D(start_neurons * 3, (3, 3,3), activation='elu', padding=\"same\")(pool3)\n",
    "    conv4 = residual_block(conv4,start_neurons * 3)\n",
    "    conv4 = residual_block(conv4,start_neurons * 3, True)\n",
    "\n",
    "\n",
    "    x1 = tf.keras.layers.GlobalMaxPooling3D(name='AvgPool_new')(conv4)\n",
    "\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "    x2 = tf.keras.layers.Dropout(0.1, name='Dropout_new')(x1)\n",
    "\n",
    "    output0 = tf.keras.layers.Dense(4, use_bias=True,activation='softmax',name='P')(x2)\n",
    "\n",
    "    model0 = tf.keras.models.Model(inputs =[inputs], outputs = [output0])\n",
    "\n",
    "    model0.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "    \n",
    "    return model0\n",
    "\n",
    "#model_no_se = resnet3DClassifier(input_shape=(10, 256, 384, 1), learningRate=0.0001, use_se_module=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the model with the SE module\n",
    "model_with_se = resnet3DClassifier(input_shape=(10, 256, 384, 1), learningRate=0.0001, use_se_module=True)\n",
    "\n",
    "#batch generator for training\n",
    "def generate_data(train_set, batch_size,shuffle=True):\n",
    "    \n",
    "    \"\"\"Replaces Keras' native ImageDataGenerator.\"\"\"\n",
    "    i = 0\n",
    "    train_ID=train_set.imagename.values\n",
    "    Y_label =train_set.label_int.values\n",
    "    batch_index=0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        image_batch = np.zeros((batch_size,10,IMG_HEIGHT,IMG_WIDTH,1))\n",
    "        Y_batch0=[]\n",
    "        Y_batch1=[]\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            \n",
    "            if i == len(train_ID):\n",
    "                \n",
    "                i = 0\n",
    "                #shuffle if u want to\n",
    "                if shuffle:\n",
    "                    \n",
    "                  train_set = train_set.sample(frac=1).reset_index(drop=True)\n",
    "                train_ID=train_set.imagename.values\n",
    "                \n",
    "                Y_label=train_set.label_int.values\n",
    "                \n",
    "            sample = train_ID[i]\n",
    "            new_image = np.load(sample)\n",
    "\n",
    "            for band in range(10):\n",
    "                \n",
    "                image_batch[b,band,:,:,0] = cv2.resize(new_image[:,:,band],(IMG_WIDTH,IMG_HEIGHT),cv2.INTER_LINEAR)\n",
    "                \n",
    "            Y_batch0.append(Y_label[i])\n",
    "            i += 1\n",
    "\n",
    "        batch_index=batch_index+1\n",
    "        image_batch=np.array(image_batch)\n",
    "        Y_batch0= np.array(Y_batch0)\n",
    "\n",
    "        yield  image_batch, Y_batch0\n",
    "        \n",
    "        \n",
    "#model_no_se = resnet3DClassifier(input_shape=(10, 256, 384, 1), learningRate=0.0001, use_se_module=False)\n",
    "#model_with_se = resnet3DClassifier(input_shape=(10, 256, 384, 1), learningRate=0.0001, use_se_module=True)\n",
    "\n",
    "\n",
    "def test():\n",
    "    \n",
    "  image_batch = np.zeros((1,10,IMG_HEIGHT,IMG_WIDTH,1))\n",
    "\n",
    "  train_ID = X_test[\"imagename\"].values\n",
    "  Y_label = X_test[\"label_int\"].values\n",
    "  Y_batch0 = []\n",
    "\n",
    "  predicted_label = []\n",
    "  \n",
    "\n",
    "  for i in range(len(X_test)):\n",
    "      \n",
    "    sample = train_ID[i]\n",
    "    new_image = np.load(sample)\n",
    "\n",
    "    for band in range(10):\n",
    "        \n",
    "        image_batch[0,band,:,:,0] = cv2.resize(new_image[:,:,band],(IMG_WIDTH,IMG_HEIGHT),cv2.INTER_LINEAR)\n",
    "\n",
    "    predict = model_with_se.predict(image_batch)\n",
    "\n",
    "    predicted_label.append(np.argmax(predict[0]))\n",
    "    Y_batch0.append(Y_label[i])\n",
    "\n",
    "\n",
    "    print(classification_report(Y_batch0,predicted_label))\n",
    "    \n",
    "    \n",
    "# Define both models without and with SE module\n",
    "\n",
    "#model_no_se = resnet3DClassifier(input_shape=(10, 256, 384, 1), learningRate=0.0001, use_se_module=False)\n",
    "model_with_se = resnet3DClassifier(input_shape=(10, 200, 200, 1), learningRate=0.0001, use_se_module=True)\n",
    "\n",
    "\n",
    "\n",
    "# Define callbacks\n",
    "\n",
    "#filepath_no_se = \"Weights-resnet3D_SqueezeClassifier-HyperSpectral-Recognition_no_SE_32.hdf5\"\n",
    "#checkpoint_no_se = tf.keras.callbacks.ModelCheckpoint(filepath_no_se, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
    "#reduce_lr_no_se = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n",
    "#callbacks_list_no_se = [checkpoint_no_se, reduce_lr_no_se]\n",
    "\n",
    "filepath_with_se = \"Weights-resnet3D_SqueezeClassifier-HyperSpectral-Recognition_with_SE_32.hdf5\"\n",
    "checkpoint_with_se = tf.keras.callbacks.ModelCheckpoint(filepath_with_se, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
    "reduce_lr_with_se = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n",
    "callbacks_list_with_se = [checkpoint_with_se, reduce_lr_with_se]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafin\\AppData\\Local\\Temp\\ipykernel_17596\\2112890698.py:17: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist_with_se = model_with_se.fit_generator(generate_data(X_train, BATCH_SIZE, True),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 1: val_loss did not improve from inf\n",
      "40/40 [==============================] - 25s 379ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.2000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 2: val_loss did not improve from inf\n",
      "40/40 [==============================] - 14s 362ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.2000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 3: val_loss did not improve from inf\n",
      "40/40 [==============================] - 14s 363ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.1000 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 4: val_loss did not improve from inf\n",
      "40/40 [==============================] - 14s 363ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.3000 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 5: val_loss did not improve from inf\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "40/40 [==============================] - 15s 364ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 6: val_loss did not improve from inf\n",
      "40/40 [==============================] - 15s 365ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.3000 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 7: val_loss did not improve from inf\n",
      "40/40 [==============================] - 15s 366ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.1000 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 8: val_loss did not improve from inf\n",
      "40/40 [==============================] - 15s 367ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.4000 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 9: val_loss did not improve from inf\n",
      "40/40 [==============================] - 15s 366ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.2000 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 10: val_loss did not improve from inf\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "40/40 [==============================] - 15s 367ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.1000 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 11: val_loss did not improve from inf\n",
      "40/40 [==============================] - 15s 367ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.2000 - lr: 1.0000e-05\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 12: val_loss did not improve from inf\n",
      "40/40 [==============================] - 15s 369ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.3000 - lr: 1.0000e-05\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 13: val_loss did not improve from inf\n",
      "40/40 [==============================] - 15s 368ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.1000 - lr: 1.0000e-05\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 14: val_loss did not improve from inf\n",
      "40/40 [==============================] - 15s 368ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.3000 - lr: 1.0000e-05\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 15: val_loss did not improve from inf\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "40/40 [==============================] - 15s 368ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.2000 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 16: val_loss did not improve from inf\n",
      "40/40 [==============================] - 15s 369ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.2000 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 17: val_loss did not improve from inf\n",
      "40/40 [==============================] - 15s 369ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.3000 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 18: val_loss did not improve from inf\n",
      "40/40 [==============================] - 15s 369ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.2000 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 19: val_loss did not improve from inf\n",
      "40/40 [==============================] - 15s 369ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.2000 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - ETA: 0s - loss: nan - acc: 0.2000\n",
      "Epoch 20: val_loss did not improve from inf\n",
      "40/40 [==============================] - 15s 370ms/step - loss: nan - acc: 0.2000 - val_loss: nan - val_acc: 0.2000 - lr: 1.0000e-05\n",
      "1/1 [==============================] - 1s 652ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         2\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.33      0.50      0.40         3\n",
      "weighted avg       0.44      0.67      0.53         3\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50         4\n",
      "   macro avg       0.25      0.50      0.33         4\n",
      "weighted avg       0.25      0.50      0.33         4\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      1.00      0.57         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.40         5\n",
      "   macro avg       0.13      0.33      0.19         5\n",
      "weighted avg       0.16      0.40      0.23         5\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.11      0.33      0.17         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      1.00      0.44         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.29         7\n",
      "   macro avg       0.07      0.25      0.11         7\n",
      "weighted avg       0.08      0.29      0.13         7\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      1.00      0.40         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.25         8\n",
      "   macro avg       0.06      0.25      0.10         8\n",
      "weighted avg       0.06      0.25      0.10         8\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      1.00      0.36         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.22         9\n",
      "   macro avg       0.04      0.20      0.07         9\n",
      "weighted avg       0.05      0.22      0.08         9\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      1.00      0.33         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.20        10\n",
      "   macro avg       0.04      0.20      0.07        10\n",
      "weighted avg       0.04      0.20      0.07        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rafin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Train the model without SE module\n",
    "#hist_no_se = model_no_se.fit_generator(generate_data(X_train, BATCH_SIZE, True),\n",
    "#                                      steps_per_epoch=round(len(X_train) / BATCH_SIZE),\n",
    "#                                      epochs=20,\n",
    "#                                      validation_data=generate_data(X_test, BATCH_SIZE),\n",
    " #                                      validation_steps=round(len(X_test) / BATCH_SIZE),\n",
    "  #                                     verbose=1,\n",
    "   #                                    callbacks=callbacks_list_no_se)\n",
    "\n",
    "# Test the model without SE module\n",
    "#test()\n",
    "\n",
    "#Train the model with SE module\n",
    "hist_with_se = model_with_se.fit_generator(generate_data(X_train, BATCH_SIZE, True),\n",
    "                                           steps_per_epoch=round(len(X_train) / BATCH_SIZE),\n",
    "                                           epochs=20,\n",
    "                                           validation_data=generate_data(X_test, BATCH_SIZE),\n",
    "                                           validation_steps=round(len(X_test) / BATCH_SIZE),\n",
    "                                           verbose=1,\n",
    "                                           callbacks=callbacks_list_with_se)\n",
    "\n",
    "# Test the model with SE module\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
