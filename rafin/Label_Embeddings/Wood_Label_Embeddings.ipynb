{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the text from a .txt file\n",
    "file_path = 'wood_corpus.txt'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    \n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load pre-trained RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "model = RobertaModel.from_pretrained('roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['<s>', 'Introduction', 'Ġto', 'ĠHeart', 'wood', 'Ġand', 'ĠSap', 'wood', 'Ġin', 'ĠWood', 'ĠAnat', 'omy', 'Ċ', 'Ċ', 'In', 'Ġthe', 'Ġanatomy', 'Ġof', 'Ġa', 'Ġtree', ',', 'Ġheart', 'wood', 'Ġand', 'Ġsap', 'wood', 'Ġare', 'Ġdistinct', 'Ġregions', 'Ġwithin', 'Ġthe', 'Ġtrunk', ',', 'Ġeach', 'Ġplaying', 'Ġunique', 'Ġroles', 'Ġin', 'Ġthe', 'Ġtree', \"'s\", 'Ġstructure', 'Ġand', 'Ġfunction', '.', 'ĠThese', 'Ġzones', 'Ġform', 'Ġconcent', 'ric', 'Ġlayers', 'Ġas', 'Ġthe', 'Ġtree', 'Ġgrows', ',', 'Ġwith', 'Ġsap', 'wood', 'Ġlocated', 'Ġin', 'Ġthe', 'Ġouter', 'most', 'Ġrings', 'Ġjust', 'Ġbeneath', 'Ġthe', 'Ġbark', ',', 'Ġand', 'Ġheart', 'wood', 'Ġoccupying', 'Ġthe', 'Ġcentral', ',', 'Ġolder', 'Ġportion', '.', 'ĠThe', 'Ġdistinction', 'Ġarises', 'Ġduring', 'Ġthe', 'Ġnatural', 'Ġaging', 'Ġand', 'Ġdevelopment', 'Ġof', 'Ġthe', 'Ġtree', ',', 'Ġas', 'Ġcells', 'Ġin', 'Ġthe', 'Ġsap', 'wood', 'Ġtransition', 'Ġto', 'Ġheart', 'wood', 'Ġover', 'Ġtime', '.', 'ĠBoth', 'Ġregions', 'Ġare', 'Ġvital', 'Ġfor', 'Ġthe', 'Ġtree', \"'s\", 'Ġoverall', 'Ġhealth', 'Ġand', 'Ġmechanical', 'Ġstability', ',', 'Ġbut', 'Ġthey', 'Ġdiffer', 'Ġin', 'Ġcomposition', ',', 'Ġappearance', ',', 'Ġand', 'Ġfunction', '.', 'ĠSap', 'wood', 'Ġis', 'Ġtypically', 'Ġlighter', 'Ġin', 'Ġcolor', 'Ġdue', 'Ġto', 'Ġits', 'Ġactive', 'Ġrole', 'Ġin', 'Ġtransporting', 'Ġwater', 'Ġand', 'Ġnutrients', ',', 'Ġwhile', 'Ġheart', 'wood', 'Ġis', 'Ġdarker', 'Ġand', 'Ġdens', 'er', ',', 'Ġoffering', 'Ġstructural', 'Ġsupport', 'Ġand', 'Ġresistance', 'Ġto', 'Ġdecay', '.', 'ĠUnderstanding', 'Ġthese', 'Ġcomponents', 'Ġis', 'Ġcrucial', 'Ġfor', 'Ġfields', 'Ġlike', 'Ġforestry', ',', 'Ġcarp', 'entry', ',', 'Ġand', 'Ġbot', 'any', ',', 'Ġas', 'Ġthe', 'Ġcharacteristics', 'Ġof', 'Ġheart', 'wood', 'Ġand', 'Ġsap', 'wood', 'Ġsignificantly', 'Ġinfluence', 'Ġthe', 'Ġutility', 'Ġand', 'Ġvalue', 'Ġof', 'Ġtimber', '.', 'Ċ', 'Ċ', 'Character', 'istics', 'Ġof', 'ĠSap', 'wood', 'Ċ', 'Ċ', 'S', 'ap', 'wood', ',', 'Ġalso', 'Ġknown', 'Ġas', 'Ġal', 'burn', 'um', ',', 'Ġforms', 'Ġthe', 'Ġouter', 'most', 'Ġfunctional', 'Ġrings', 'Ġof', 'Ġthe', 'Ġtree', 'âĢ', 'Ļ', 's', 'Ġtrunk', '.', 'ĠThis', 'Ġregion', 'Ġconsists', 'Ġof', 'Ġliving', 'Ġx', 'yle', 'm', 'Ġtissues', 'Ġthat', 'Ġactively', 'Ġconduct', 'Ġwater', 'Ġand', 'Ġdissolved', 'Ġnutrients', 'Ġfrom', 'Ġthe', 'Ġroots', 'Ġto', 'Ġthe', 'Ġleaves', '.', 'ĠSap', 'wood', 'Ġis', 'Ġlighter', 'Ġin', 'Ġcolor', 'Ġand', 'Ġgenerally', 'Ġsofter', 'Ġthan', 'Ġheart', 'wood', ',', 'Ġwith', 'Ġa', 'Ġtexture', 'Ġthat', 'Ġis', 'Ġmore', 'Ġuniform', 'Ġand', 'Ġless', 'Ġdense', '.', 'ĠThe', 'Ġcells', 'Ġin', 'Ġsap', 'wood', 'Ġremain', 'Ġmetabol', 'ically', 'Ġactive', ',', 'Ġcontributing', 'Ġto', 'Ġprocesses', 'Ġlike', 'Ġstorage', 'Ġof', 'Ġnutrients', 'Ġand', 'Ġdefense', 'Ġagainst', 'Ġpathogens', '.', 'ĠDue', 'Ġto', 'Ġits', 'Ġfunction', ',', 'Ġsap', 'wood', 'Ġcontains', 'Ġhigh', 'Ġmoisture', 'Ġlevels', ',', 'Ġmaking', 'Ġit', 'Ġless', 'Ġdurable', 'Ġand', 'Ġmore', 'Ġsusceptible', 'Ġto', 'Ġdecay', 'Ġcompared', 'Ġto', 'Ġheart', 'wood', '.', 'ĠIn', 'Ġmany', 'Ġtree', 'Ġspecies', ',', 'Ġsap', 'wood', 'Ġthickness', 'Ġvaries', 'Ġwith', 'Ġage', ',', 'Ġenvironmental', 'Ġconditions', ',', 'Ġand', 'Ġspecies', '-', 'specific', 'Ġgrowth', 'Ġpatterns', '.', 'ĠWhile', 'Ġits', 'Ġlighter', 'Ġcolor', 'Ġand', 'Ġlower', 'Ġdurability', 'Ġmake', 'Ġit', 'Ġless', 'Ġdesirable', 'Ġfor', 'Ġcertain', 'Ġwood', 'Ġproducts', ',', 'Ġsap', 'wood', 'âĢ', 'Ļ', 's', 'Ġease', 'Ġof', 'Ġwork', 'ability', 'Ġand', 'Ġhigh', 'Ġperme', 'ability', 'Ġmake', 'Ġit', 'Ġessential', 'Ġin', 'Ġapplications', 'Ġlike', 'Ġconstruction', 'Ġand', 'Ġthe', 'Ġproduction', 'Ġof', 'Ġpaper', 'Ġpulp', '.', 'ĠIts', 'Ġfunctional', 'Ġrole', 'Ġin', 'Ġthe', 'Ġtree', 'Ġis', 'Ġvital', ',', 'Ġas', 'Ġit', 'Ġserves', 'Ġas', 'Ġthe', 'Ġlif', 'eline', 'Ġfor', 'Ġwater', 'Ġand', 'Ġnutrient', 'Ġtransport', '.', 'Ċ', 'Ċ', 'Character', 'istics', 'Ġof', 'ĠHeart', 'wood', 'Ċ', 'Ċ', 'Heart', 'wood', ',', 'Ġoften', 'Ġreferred', 'Ġto', 'Ġas', 'Ġdur', 'amen', ',', 'Ġis', 'Ġthe', 'Ġcentral', ',', 'Ġnon', '-', 'living', 'Ġportion', 'Ġof', 'Ġthe', 'Ġtree', 'Ġtrunk', '.', 'ĠAs', 'Ġsap', 'wood', 'Ġcells', 'Ġage', ',', 'Ġthey', 'Ġtransition', 'Ġinto', 'Ġheart', 'wood', 'Ġthrough', 'Ġa', 'Ġprocess', 'Ġcalled', 'Ġheart', 'wood', 'Ġformation', ',', 'Ġduring', 'Ġwhich', 'Ġthey', 'Ġdie', 'Ġand', 'Ġbecome', 'Ġinfused', 'Ġwith', 'Ġres', 'ins', ',', 'Ġt', 'ann', 'ins', ',', 'Ġand', 'Ġother', 'Ġsecondary', 'Ġmetabolites', '.', 'ĠThese', 'Ġcompounds', 'Ġdark', 'en', 'Ġthe', 'Ġwood', 'Ġand', 'Ġimpart', 'Ġnatural', 'Ġresistance', 'Ġto', 'Ġdecay', ',', 'Ġfungi', ',', 'Ġand', 'Ġinsects', ',', 'Ġmaking', 'Ġheart', 'wood', 'Ġhighly', 'Ġvalued', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Tokenize the text\n",
    "inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "\n",
    "#see tokens:\n",
    "input_ids = inputs['input_ids'][0]\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "print(\"Tokens:\", tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for heartwood  : tensor([ 0.2567,  0.2757, -0.2582,  ...,  0.0249,  0.3811,  0.2583])\n",
      "Embedding for sapwood  : tensor([ 0.2408,  0.2505, -0.2593,  ...,  0.0568,  0.3598,  0.2458])\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Extract embeddings\n",
    "# Get the tokenized input IDs and attention mask\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "\n",
    "# Run the inputs through the model\n",
    "with torch.no_grad():\n",
    "    \n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    # Get the last hidden states (embeddings for each token)\n",
    "    embeddings = outputs.last_hidden_state\n",
    "\n",
    "# Choose the two words you want to extract embeddings for\n",
    "word_1 = \"heartwood\"\n",
    "word_2 = \"sapwood\"\n",
    "\n",
    "# Tokenize the individual words\n",
    "word_1_id = tokenizer.encode(word_1, add_special_tokens=False)\n",
    "word_2_id = tokenizer.encode(word_2, add_special_tokens=False)\n",
    "\n",
    "# Find the indices of these words in the tokenized input\n",
    "indices_word_1 = [i for i, id_ in enumerate(input_ids[0]) if id_ in word_1_id]\n",
    "indices_word_2 = [i for i, id_ in enumerate(input_ids[0]) if id_ in word_2_id]\n",
    "\n",
    "# Extract embeddings for the specific words\n",
    "embedding_word_1 = embeddings[0, indices_word_1, :].mean(dim=0) if indices_word_1 else None\n",
    "embedding_word_2 = embeddings[0, indices_word_2, :].mean(dim=0) if indices_word_2 else None\n",
    "\n",
    "# Output the embeddings\n",
    "print(\"Embedding for\", word_1,\" :\", embedding_word_1)\n",
    "print(\"Embedding for\", word_2,\" :\", embedding_word_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: [[0.9996097]]\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(embedding_word_1.unsqueeze(0), embedding_word_2.unsqueeze(0))\n",
    "print(\"Cosine Similarity:\", similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
