{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_path = 'C:/Users/rafin/Desktop/NSU/NSU 12th Semester/CSE499A.22/Project/Datasets/Apple_Datasets/Apple_HS_BIL_Roi_Masked_npy_2'\n",
    "#data_path = 'C:/Users/rafin/Desktop/NSU/NSU 12th Semester/CSE499A.22/Project/Datasets/LadyFinger_Datasets/LF_BIL_npy'\n",
    "\n",
    "image_list = []\n",
    "label_list = []\n",
    "label_int =[]\n",
    "\n",
    "for i, folder in enumerate(os.listdir(data_path)):\n",
    "    \n",
    "  images = os.listdir(f\"{data_path}/\")\n",
    "  \n",
    "  for row in range(len(images)):\n",
    "      \n",
    "    image_list.append(f\"{data_path}/\" + images[i])\n",
    "    label_list.append(folder)\n",
    "    label_int.append(i)\n",
    "    \n",
    "{i:x for i, x in enumerate(os.listdir(data_path))}\n",
    "\n",
    "sub = pd.DataFrame(image_list)\n",
    "sub.columns = [\"imagename\"]\n",
    "\n",
    "sub[\"label_int\"] = label_int\n",
    "sub[\"label_list\"] = label_list\n",
    "\n",
    "sub.to_csv(\"dataset.csv\")\n",
    "\n",
    "sub.label_int.unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data_path = 'C:/Users/rafin/Desktop/NSU/NSU 12th Semester/CSE499A.22/Project/Datasets/Apple_Datasets/Apple_HS_BIL_Roi_Masked_npy'\n",
    "\n",
    "image_list = []\n",
    "label_list = []\n",
    "label_int =[]\n",
    "\n",
    "for i, folder in enumerate(os.listdir(data_path)):\n",
    "    \n",
    "  images = os.listdir(f\"{data_path}/\" + folder + \"/\")\n",
    "  \n",
    "  for row in range(len(images)):\n",
    "      \n",
    "    image_list.append(f\"{data_path}/\" + folder + \"/\" + images[row])\n",
    "    \n",
    "    label_list.append(folder)\n",
    "    label_int.append(i)\n",
    "    \n",
    "{i:x for i, x in enumerate(os.listdir(data_path))}\n",
    "\n",
    "sub = pd.DataFrame(image_list)\n",
    "sub.columns = [\"imagename\"]\n",
    "\n",
    "sub[\"label_int\"] = label_int\n",
    "sub[\"label_list\"] = label_list\n",
    "\n",
    "sub.to_csv(\"dataset.csv\")\n",
    "sub.label_int.unique()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "X = sub[\"imagename\"].values\n",
    "y = sub[\"label_int\"].values\n",
    "\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "\n",
    "     X_train, X_test = sub.iloc[train_index], sub.iloc[test_index]\n",
    "     y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "print(X.shape)\n",
    "print(X_train.shape , X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 384\n",
    "IMG_CHANNELS = 1\n",
    "IMG_COUNT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchActivate(x):\n",
    "    \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('elu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1,1), padding='same', activation=True):\n",
    "    \n",
    "    x = tf.keras.layers.Conv3D(filters, size, strides=strides, padding=padding,kernel_initializer='Orthogonal')(x)\n",
    "    \n",
    "    if activation == True:\n",
    "        \n",
    "        x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def residual_block_dual(blockInput, num_filters=16, batch_activate = False):\n",
    "\n",
    "    x_side = convolution_block(blockInput, num_filters,(3,3,3))\n",
    "\n",
    "    x = BatchActivate(blockInput)\n",
    "    x1 = convolution_block(x, num_filters, (3,3,3) ,activation=False)\n",
    "\n",
    "    x2 = convolution_block(x1, num_filters, (3,3,3), activation=False)\n",
    "    x2 = BatchActivate(x2)\n",
    "    x2_add = tf.keras.layers.Add()([x1,x2])\n",
    "    \n",
    "    x3 = convolution_block(x2_add, num_filters, (5,5,5), activation=False)\n",
    "    x3 = tf.keras.layers.Add()([x3,x_side])\n",
    "    \n",
    "    x4 = convolution_block(x3, num_filters, (3,3,3), activation=False)\n",
    "\n",
    "#    x = Add()([Squeeze_excitation_layer(x4),x_side])\n",
    "    if batch_activate:\n",
    "        \n",
    "        x4 = BatchActivate(x4)\n",
    "    return x4\n",
    "\n",
    "def residual_block(blockInput, num_filters=16, batch_activate = False):\n",
    "\n",
    "    x_side = convolution_block(blockInput, num_filters,(3,3,3))\n",
    "\n",
    "    x = BatchActivate(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3,3) ,activation=True)\n",
    "#    x = PReLU(shared_axes=[1, 2])(x)\n",
    "\n",
    "    x= convolution_block(x, num_filters, (3,3,3), activation=True)\n",
    "\n",
    "#    x = convolution_block(x, num_filters, (3,3), activation=True)\n",
    "\n",
    "#    x = BatchActivate(x)\n",
    "    x=Squeeze_excitation_layer_3D(x)\n",
    "    \n",
    "    x = tf.keras.layers.Add()([x,x_side])\n",
    "    \n",
    "    if batch_activate:\n",
    "        \n",
    "        x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def Squeeze_excitation_layer_3D(input_x):\n",
    "    \n",
    "    ratio = 4\n",
    "    out_dim =  int(np.shape(input_x)[-1])\n",
    "    \n",
    "    squeeze = tf.keras.layers.GlobalAveragePooling3D()(input_x)\n",
    "    \n",
    "    excitation = tf.keras.layers.Dense(units=int(out_dim / ratio))(squeeze)\n",
    "    excitation = tf.keras.layers.Activation('relu')(excitation)\n",
    "    excitation = tf.keras.layers.Dense(units=out_dim)(excitation)\n",
    "    excitation = tf.keras.layers.Activation('sigmoid')(excitation)\n",
    "    excitation = tf.keras.layers.Reshape([-1,1,1,out_dim])(excitation)\n",
    "    \n",
    "    scale = tf.keras.layers.multiply([input_x, excitation])\n",
    "\n",
    "    return scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet3DClassifier(input_shape=(IMG_COUNT,IMG_HEIGHT, IMG_WIDTH,IMG_CHANNELS),learningRate=0.001,use_se_module=True):\n",
    "\n",
    "    dropout_keep_prob =0.1\n",
    "    '''\n",
    "\n",
    "    Network with multiple attention\n",
    "\n",
    "    '''\n",
    "    start_neurons=32\n",
    "    DropoutRatio = 0.2\n",
    "    inputs = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "\n",
    "\n",
    "#    coord0=CoordinateChannel2D()(inputs)\n",
    "    # 101 -> 50\n",
    "    conv1 = tf.keras.layers.Conv3D(start_neurons, (3,3,3), activation='elu', padding=\"same\")(inputs)\n",
    "    conv1 = residual_block(conv1,start_neurons,True)\n",
    "    conv1 = residual_block(conv1,start_neurons, True)\n",
    "#    conv1=csse_block(conv1,'prefix_conv_1')\n",
    "\n",
    "\n",
    "#    conv1 = nonLocalAttention(conv1)\n",
    "    pool1 = tf.keras.layers.MaxPooling3D((2, 2,2))(conv1)\n",
    "    pool1 = tf.keras.layers.Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    # 50 -> 25\n",
    "    conv2 = tf.keras.layers.Conv3D(start_neurons * 1, (3,3,3), activation='elu', padding=\"same\")(pool1)\n",
    "    conv2 = residual_block(conv2,start_neurons * 1,True)\n",
    "    conv2 = residual_block(conv2,start_neurons * 1, True)\n",
    "\n",
    "    pool2 = tf.keras.layers.MaxPooling3D((2, 2,2))(conv2)\n",
    "    pool2 = tf.keras.layers.Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "#    # 25 -> 12\n",
    "    conv3 = tf.keras.layers.Conv3D(start_neurons * 2, (3,3,3), activation='elu', padding=\"same\")(pool2)\n",
    "    conv3 = residual_block(conv3,start_neurons * 2)\n",
    "    conv3 = residual_block(conv3,start_neurons * 2, True)\n",
    "\n",
    "\n",
    "    pool3 = tf.keras.layers.MaxPooling3D((2,2,2))(conv3)\n",
    "    pool3 = tf.keras.layers.Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "#    # 12 -> 6\n",
    "    conv4 = tf.keras.layers.Conv3D(start_neurons * 3, (3, 3,3), activation='elu', padding=\"same\")(pool3)\n",
    "    conv4 = residual_block(conv4,start_neurons * 3)\n",
    "    conv4 = residual_block(conv4,start_neurons * 3, True)\n",
    "\n",
    "\n",
    "    x1 = tf.keras.layers.GlobalMaxPooling3D(name='AvgPool_new')(conv4)\n",
    "\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "    x2 = tf.keras.layers.Dropout(0.1, name='Dropout_new')(x1)\n",
    "\n",
    "    output0 = tf.keras.layers.Dense(4, use_bias=True,activation='softmax',name='P')(x2)\n",
    "\n",
    "    model0 = tf.keras.models.Model(inputs =[inputs], outputs = [output0])\n",
    "\n",
    "    model0.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\n",
    "    \n",
    "    return model0\n",
    "\n",
    "#model_no_se = resnet3DClassifier(input_shape=(10, 256, 384, 1), learningRate=0.0001, use_se_module=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model with the SE module\n",
    "model_with_se = resnet3DClassifier(input_shape=(10, 256, 384, 1), learningRate=0.0001, use_se_module=True)\n",
    "\n",
    "#batch generator for training\n",
    "def generate_data(train_set, batch_size,shuffle=True):\n",
    "    \n",
    "    \"\"\"Replaces Keras' native ImageDataGenerator.\"\"\"\n",
    "    i = 0\n",
    "    train_ID=train_set.imagename.values\n",
    "    Y_label =train_set.label_int.values\n",
    "    batch_index=0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        image_batch = np.zeros((batch_size,10,IMG_HEIGHT,IMG_WIDTH,1))\n",
    "        Y_batch0=[]\n",
    "        Y_batch1=[]\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            \n",
    "            if i == len(train_ID):\n",
    "                \n",
    "                i = 0\n",
    "                #shuffle if u want to\n",
    "                if shuffle:\n",
    "                    \n",
    "                  train_set = train_set.sample(frac=1).reset_index(drop=True)\n",
    "                train_ID=train_set.imagename.values\n",
    "                \n",
    "                Y_label=train_set.label_int.values\n",
    "                \n",
    "            sample = train_ID[i]\n",
    "            new_image = np.load(sample)\n",
    "\n",
    "            for band in range(10):\n",
    "                \n",
    "                image_batch[b,band,:,:,0] = cv2.resize(new_image[:,:,band],(IMG_WIDTH,IMG_HEIGHT),cv2.INTER_LINEAR)\n",
    "                \n",
    "            Y_batch0.append(Y_label[i])\n",
    "            i += 1\n",
    "\n",
    "        batch_index=batch_index+1\n",
    "        image_batch=np.array(image_batch)\n",
    "        Y_batch0= np.array(Y_batch0)\n",
    "\n",
    "        yield  image_batch, Y_batch0\n",
    "        \n",
    "        \n",
    "#model_no_se = resnet3DClassifier(input_shape=(10, 256, 384, 1), learningRate=0.0001, use_se_module=False)\n",
    "model_with_se = resnet3DClassifier(input_shape=(10, 256, 384, 1), learningRate=0.0001, use_se_module=True)\n",
    "\n",
    "\n",
    "def test():\n",
    "    \n",
    "  image_batch = np.zeros((1,10,IMG_HEIGHT,IMG_WIDTH,1))\n",
    "\n",
    "  train_ID = X_test[\"imagename\"].values\n",
    "  Y_label = X_test[\"label_int\"].values\n",
    "  Y_batch0 = []\n",
    "\n",
    "  predicted_label = []\n",
    "  \n",
    "\n",
    "  for i in range(len(X_test)):\n",
    "      \n",
    "    sample = train_ID[i]\n",
    "    new_image = np.load(sample)\n",
    "\n",
    "    for band in range(10):\n",
    "        \n",
    "        image_batch[0,band,:,:,0] = cv2.resize(new_image[:,:,band],(IMG_WIDTH,IMG_HEIGHT),cv2.INTER_LINEAR)\n",
    "\n",
    "    predict = model_with_se.predict(image_batch)\n",
    "\n",
    "    predicted_label.append(np.argmax(predict[0]))\n",
    "    Y_batch0.append(Y_label[i])\n",
    "\n",
    "\n",
    "    print(classification_report(Y_batch0,predicted_label))\n",
    "    \n",
    "    \n",
    "# Define both models without and with SE module\n",
    "\n",
    "#model_no_se = resnet3DClassifier(input_shape=(10, 256, 384, 1), learningRate=0.0001, use_se_module=False)\n",
    "model_with_se = resnet3DClassifier(input_shape=(10, 256, 384, 1), learningRate=0.0001, use_se_module=True)\n",
    "\n",
    "\n",
    "\n",
    "# Define callbacks\n",
    "\n",
    "#filepath_no_se = \"Weights-resnet3D_SqueezeClassifier-HyperSpectral-Recognition_no_SE_32.hdf5\"\n",
    "#checkpoint_no_se = tf.keras.callbacks.ModelCheckpoint(filepath_no_se, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
    "#reduce_lr_no_se = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n",
    "#callbacks_list_no_se = [checkpoint_no_se, reduce_lr_no_se]\n",
    "\n",
    "filepath_with_se = \"Weights-resnet3D_SqueezeClassifier-HyperSpectral-Recognition_with_SE_32.hdf5\"\n",
    "checkpoint_with_se = tf.keras.callbacks.ModelCheckpoint(filepath_with_se, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
    "reduce_lr_with_se = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n",
    "callbacks_list_with_se = [checkpoint_with_se, reduce_lr_with_se]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Train the model without SE module\n",
    "#hist_no_se = model_no_se.fit_generator(generate_data(X_train, BATCH_SIZE, True),\n",
    "#                                      steps_per_epoch=round(len(X_train) / BATCH_SIZE),\n",
    "#                                      epochs=20,\n",
    "#                                      validation_data=generate_data(X_test, BATCH_SIZE),\n",
    " #                                      validation_steps=round(len(X_test) / BATCH_SIZE),\n",
    "  #                                     verbose=1,\n",
    "   #                                    callbacks=callbacks_list_no_se)\n",
    "\n",
    "# Test the model without SE module\n",
    "#test()\n",
    "\n",
    "#Train the model with SE module\n",
    "hist_with_se = model_with_se.fit_generator(generate_data(X_train, BATCH_SIZE, True),\n",
    "                                           steps_per_epoch=round(len(X_train) / BATCH_SIZE),\n",
    "                                           epochs=20,\n",
    "                                           validation_data=generate_data(X_test, BATCH_SIZE),\n",
    "                                           validation_steps=round(len(X_test) / BATCH_SIZE),\n",
    "                                           verbose=1,\n",
    "                                           callbacks=callbacks_list_with_se)\n",
    "\n",
    "# Test the model with SE module\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
