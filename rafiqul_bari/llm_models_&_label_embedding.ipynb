{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentence-transformers gensim nltk scikit-learn\n"
      ],
      "metadata": {
        "id": "X5GgjjjumAXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "# Download the 'punkt_tab' data package\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sentence_transformers import SentenceTransformer\n"
      ],
      "metadata": {
        "id": "CqhTmCqvijqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of labels\n",
        "\n",
        "#labels = [\"Hypolimnas\", \"Misippus\", \"Danaus\", \"Chrysippus\", \"Amauris\", \"Ochlea\", \"Acraea\", \"Egina\"]\n",
        "labels = [\"Hypolimnas Misippus\", \"Danaus Chrysippus\", \"Amauris Ochlea\", \"Acraea Egina\"]"
      ],
      "metadata": {
        "id": "VWMHWpLAgXEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Contextual Paragraphs Using an LLM"
      ],
      "metadata": {
        "id": "vbqyeXezm0gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Qwen2.5-1.5B-Instruct model and tokenizer        #most download\n",
        "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True).half().cuda()\n",
        "\n",
        "# Function to generate text for a label\n",
        "def generate_paragraph(label):\n",
        "    prompt = f\"Write a descriptive paragraph about {label}.\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=250, temperature=0.7)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "# Generate paragraphs for each label\n",
        "contextual_paragraphs_Qwen1_5B = {label: generate_paragraph(label) for label in labels}\n",
        "\n",
        "# Print the generated paragraphs\n",
        "for label, paragraph in contextual_paragraphs_Qwen1_5B.items():\n",
        "    print(f\"{label}: {paragraph}\\n\")\n"
      ],
      "metadata": {
        "id": "-1YEs2lk2lp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load a GPT-Neo model for text generation\n",
        "generator = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-1.3B\", device=0)\n",
        "\n",
        "# Define your labels\n",
        "labels = [\"cat\", \"dog\", \"bird\"]\n",
        "\n",
        "# Generate contextual paragraphs for each label\n",
        "contextual_paragraphs_gpt_neo = {}\n",
        "for label in labels:\n",
        "    prompt = f\"Write a descriptive paragraph about {label}.\"\n",
        "    response = generator(prompt, max_length=100, num_return_sequences=1,truncation=True)\n",
        "    contextual_paragraphs_gpt_neo[label] = response[0]['generated_text']\n",
        "\n",
        "# Print results\n",
        "for label, text in contextual_paragraphs_gpt_neo.items():\n",
        "    print(f\"{label}: {text}\\n\")\n",
        "'''"
      ],
      "metadata": {
        "id": "upL1O593otiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load the NuExtract-1.5-smol model and tokenizer\n",
        "model_name = \"numind/NuExtract-1.5-smol\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True).cuda()\n",
        "\n",
        "# Function to generate text for a label\n",
        "def generate_paragraph(label):\n",
        "    prompt = f\"Write a detailed and descriptive paragraph about {label}.\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=100, temperature=0.7)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# List of labels\n",
        "labels = [\"cat\", \"dog\", \"bird\"]\n",
        "\n",
        "# Generate paragraphs for each label\n",
        "contextual_paragraphs_numind = {label: generate_paragraph(label) for label in labels}\n",
        "\n",
        "# Print the generated paragraphs\n",
        "for label, paragraph in contextual_paragraphs_numind.items():\n",
        "    print(f\"{label}: {paragraph}\\n\")\n",
        "'''"
      ],
      "metadata": {
        "id": "gDeQmFxRCMur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Prepare Corpus for Word Embedding"
      ],
      "metadata": {
        "id": "O_S0WN1ZnC27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine the generated paragraphs into a single corpus"
      ],
      "metadata": {
        "id": "2VKNfRawnG3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"\\n\".join(contextual_paragraphs_Qwen1_5B.values())\n",
        "print(corpus)\n"
      ],
      "metadata": {
        "id": "s0Xt7g5Do2cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Word Embeddings"
      ],
      "metadata": {
        "id": "pLEwZTDMnRzS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec Embeddings"
      ],
      "metadata": {
        "id": "kHPjDNrXnWR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the corpus into sentences\n",
        "sentences = [word_tokenize(paragraph.lower()) for paragraph in contextual_paragraphs_Qwen1_5B.values()]\n",
        "\n",
        "# Train Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Retrieve embeddings for each label\n",
        "label_embeddings = {label: word2vec_model.wv[label] for label in labels}\n",
        "print(label_embeddings)"
      ],
      "metadata": {
        "id": "ifvdCbGWq6z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT Embeddings"
      ],
      "metadata": {
        "id": "fEZr69NwnYQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained BERT model\n",
        "bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Generate embeddings for each label's paragraph\n",
        "label_embeddings_b = {label: bert_model.encode(paragraph) for label, paragraph in contextual_paragraphs_Qwen1_5B.items()}\n",
        "print(label_embeddings_b)\n"
      ],
      "metadata": {
        "id": "6Ihw6KRRrICd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate embeddings by averaging\n",
        "final_vector = np.mean(list(label_embeddings.values()), axis=0)\n",
        "print(\"Final Word2Vec Vector Shape:\", final_vector.shape)"
      ],
      "metadata": {
        "id": "ZKCP2zcsvSba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate embeddings by averaging\n",
        "final_vector = np.mean(list(label_embeddings_b.values()), axis=0)\n",
        "print(\"Final BERT Vector Shape:\", final_vector.shape)"
      ],
      "metadata": {
        "id": "aohkl7mzvzuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Save final vector\n",
        "np.save(\"final_vector.npy\", final_vector)\n",
        "'''"
      ],
      "metadata": {
        "id": "1kufzvrgvnjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract embeddings\n",
        "embeddings = list(label_embeddings.values())\n",
        "label_names = list(label_embeddings.keys())\n",
        "\n",
        "# Reduce dimensionality\n",
        "pca = PCA(n_components=2)\n",
        "reduced_embeddings = pca.fit_transform(embeddings)\n",
        "\n",
        "# Plot the embeddings\n",
        "plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], marker='o')\n",
        "\n",
        "for i, label in enumerate(label_names):\n",
        "    plt.annotate(label, (reduced_embeddings[i, 0], reduced_embeddings[i, 1]))\n",
        "\n",
        "plt.title(\"Label Embeddings Visualization\")\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "Q8vGy-G_rr7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GitCkrjhsxE1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}